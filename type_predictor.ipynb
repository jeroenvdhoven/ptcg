{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop a couple of bad records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"card_file_name\"].isin([\n",
    "    \"data/pictures/Mysterious Treasures/Honchkrow_(Mysterious_Treasures_10)\",\n",
    "    \"data/pictures/Unified Minds/Umbreon_%26_Darkrai-GX_(Unified_Minds_125)\", # missing on website\n",
    "    \"data/pictures/Base Set/Charizard_(Base_Set_4)\", # special version of normal website\n",
    "    \"data/pictures/Stormfront/Charizard_(Stormfront_103)\", # special version of normal website\n",
    "])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter to Pokemon types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.type.value_counts()\n",
    "df = df[df[\"type\"].isin([\n",
    "    \"Water\",\n",
    "    \"Grass\",\n",
    "    \"Colorless\",\n",
    "    \"Psychic\",\n",
    "    \"Fighting\",\n",
    "    \"Fire\",\n",
    "    \"Lightning\",\n",
    "    \"Darkness\",\n",
    "    \"Metal\",\n",
    "    \"Dragon\",\n",
    "    \"Fairy\",\n",
    "])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess each image\n",
    "def parse_image_file(filename, label = None):\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.cast(tf.image.decode_jpeg(img, channels=3), tf.float32) / 255.0\n",
    "    \n",
    "#     if img.shape[0] < 50:\n",
    "#         print(f\"Error with image `{filename}`: shape found was small: {img.shape}\")\n",
    "    img = tf.image.resize_with_crop_or_pad(img, 260, 180)\n",
    "    \n",
    "    # Some images have an extra alpha channel. Remove that.\n",
    "    img = img[:, :, :3]\n",
    "    \n",
    "    if label is None: return img\n",
    "    else: return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if 'x' in locals():\n",
    "#     del x\n",
    "# x = tf.stack([\n",
    "#     parse_image_file(f) for f in df[\"card_file_name\"].values\n",
    "# ], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames, indices = np.unique(df[\"type\"].values, return_inverse=True)\n",
    "\n",
    "y = keras.utils.to_categorical(\n",
    "        indices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = y.shape[-1]\n",
    "n_records = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_data = tf.data.Dataset.from_tensor_slices(\n",
    "#   (x, y)\n",
    "# ).shuffle(10000)\n",
    "\n",
    "# del x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = tf.constant(df[\"card_file_name\"].values)\n",
    "\n",
    "all_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (x, y)\n",
    ").map(parse_image_file).shuffle(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frac = .7\n",
    "batch_size = 50\n",
    "\n",
    "train = all_data.take(int(train_frac * n_records)).batch(batch_size)\n",
    "remaining_data = all_data.skip(int(train_frac * n_records))\n",
    "\n",
    "validate = remaining_data.take(int(.5 * (1 - train_frac) * n_records)).batch(batch_size)\n",
    "test = remaining_data.skip(int(.5 * (1 - train_frac) * n_records)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x, y in test:\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=10, kernel_size=5, strides=2),\n",
    "    keras.layers.MaxPool2D(),\n",
    "    keras.layers.Conv2D(filters=10, kernel_size=5, strides=2),\n",
    "    keras.layers.MaxPool2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=30, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=30, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=n_classes, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Nadam(learning_rate=.001),\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.categorical_accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.fit(train, validation_data=validate, epochs=5, shuffle=True)\n",
    "finally:\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a couple of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_converter(label):\n",
    "    return tf.math.argmax(label, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_predict(img):\n",
    "    assert img.shape[0] == 1, \"Please only provide a single image at a time\"\n",
    "    \n",
    "    prediction = model.predict(img)\n",
    "    class_index = label_converter(prediction)\n",
    "    class_name = classnames[class_index[0]]\n",
    "    \n",
    "    plt.imshow(img[0])\n",
    "    plt.title(class_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for vis_x, _ in train.take(1):\n",
    "    for i in range(vis_x.shape[0]):\n",
    "        plot_and_predict(vis_x[i:i+1])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
